{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Red Neuronal Crimen Economia.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filosoficaguilar/RedNeuronalCrimenEconomia/blob/master/Red_Neuronal_Crimen_Economia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u0uGh1GzVEN",
        "colab_type": "text"
      },
      "source": [
        "En el presente documento encontrara los pasos a seguir para la obtencion de datos que habran de alimentar a una red neuronal con el fin de generar un modelo matematico y una serie de proyecciones de datos.\n",
        "\n",
        "El punto central del presente documento es generar una red neuronal y su correspondiente modelo matematico que liga la relacion crimen y economia en la ciudad de mexico, usando datos de referencia del lapso 1997 a 2017."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggvpiFwbwm1A",
        "colab_type": "text"
      },
      "source": [
        "Se instalan las dependencias correspondientes para poder hacer uso se pymongo (libreria de mongodb en python) y tabula (conversor de PDF a dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79HaLrL6_P_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install tabula-py\n",
        "! python -m pip install pymongo==3.7.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xmpk1lNClfW",
        "colab_type": "text"
      },
      "source": [
        "Para la correcta creacion de la red neuronal, se debe tener en consideracion la obtencion de datos, asi como su espacio de almacenamiento y su relacion, por otra parte se debe entablar el modelo matematico y sus funciones, para ello y en primera instancia nos debemos asegurar de importar todas las librerias necesarias, mismas se muestran a continuacion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMKfZO39CiKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DEPENDENCIAS\n",
        "\n",
        "import io #\n",
        "import os #\n",
        "import re\n",
        "import json\n",
        "import pymongo #Base de datos no relacional (MongoDB)\n",
        "import requests #Libreria para el manejo de request a una pagina web\n",
        "import datetime # Importamos la libreria de datatime\n",
        "import pymongo\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as pltm\n",
        "from bs4 import BeautifulSoup #\n",
        "from google.colab import files\n",
        "from google_drive_downloader import GoogleDriveDownloader as gd #Libreria de google drive para descargar ficheros a partir de su id\n",
        "from tabula import read_pdf #Libreria para la lectura de un documento pdf\n",
        "from pymongo import MongoClient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxzHSCdLEiEe",
        "colab_type": "text"
      },
      "source": [
        "Se genera la conexion local a Mongo para la creacion de la base de datos,la conexion con mongo se esta dando con un usuario de esta investigación, sin embargo siempre se puede cambiar ya que el usuario que nosotros prestamos es de solo lectura, si lo que quiere es guardar la información resultante de cada uno de los dataset es necesario que genere su propia BD en mongoDB, para ello lo puede hacer creando una cuenta en [mLab](https://mlab.com) el cual es un gestor de bases de datos no relacionales propio de MongoUniversity, de igual manera debera generar la conexion con el siguiente codigo.\n",
        "\n",
        "\n",
        "```\n",
        "uri = \"mongodb://<user>:<password>@<server>:<port>/<bd>?retryWrites=false\"\n",
        "client = MongoClient( uri ) \n",
        "db = client[\"bd\"]\n",
        "\n",
        "#Paga generar una insercion es necesario poner el siguiente codigo\n",
        "db[\"collection\"].insert_many()\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M14eJYSpCfwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CONEXION CON BASE DE DATOS\n",
        "\n",
        "uri = \"mongodb://readerUTC:UTCpassword1@ds149218.mlab.com:49218/tesis_red_neuronal?retryWrites=false\"\n",
        "client = MongoClient( uri ) # Se inicializa al cliente para establecer la conexion con mongo\n",
        "db = client[\"tesis_red_neuronal\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xWo1dGLx7ju",
        "colab_type": "text"
      },
      "source": [
        "Se obtienen y procesan los datos criminales obtenidos directamente del gobierno de la ciudad de México."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IM_-nlX_ApL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GUARDADO DE DATOS CRIMINALISTICOS\n",
        "def noPdf():\n",
        "    for i in range(1997,2017):\n",
        "        name = str(i)+\".pdf\"\n",
        "        if os.path.exists(\"./\"+name):\n",
        "            os.remove(\"./\"+name)\n",
        "def datos(): \n",
        "    #Declaramos la URL de donde se van a obtener los link de los documentos\n",
        "    url='https://www.gob.mx/sesnsp/acciones-y-programas/incidencia-delictiva-del-fuero-comun?idiom=es'\n",
        "    links = []\n",
        "    #Abrimos la url con el metodo GET\n",
        "    resp=requests.get(url) \n",
        "      \n",
        "    #Validamos el status de la conexion, si es un status 200 entonces proseguimos\n",
        "    if resp.status_code==200: \n",
        "        print(\"Se conecto Correctamente a la fuente\\n\") \n",
        "        #Convertimos la pagina a texto con todas sus etiquetas\n",
        "        soup=BeautifulSoup(resp.text,'html.parser')     \n",
        "        #Buscamos los elementos donde se han visualizado los link\n",
        "        l=soup.find(\"div\",{\"class\",\"article-body\"}) \n",
        "        #Se recorren los elementos \n",
        "        for i in l.findAll(\"li\"):\n",
        "            #Se valida que sean solo numeros la descripcion que lleva ese elemetno de lista\n",
        "            try:\n",
        "              if(i.a.text.isdigit()):\n",
        "                  #Se divide la url completa de el identificador de google drive\n",
        "                  splited = i.a[\"href\"].split(\"=\")\n",
        "                  name = i.a.text\n",
        "                  #Se añade el nombre y el id del documento al arreglo de documentos\n",
        "                  links.append({\"name\":name,\"id\":splited[1]})\n",
        "            except:\n",
        "              pass\n",
        "    else: \n",
        "        print(\"Error\")\n",
        "    #Se retorna el arreglo con los nombres y ids de los documentos\n",
        "    return links\n",
        "\n",
        "def getDocumentsCrimen(datos):\n",
        "    delitos = []\n",
        "    diccionario = [\"TOTAL DE ROBOS\", \"ROBO COMUN\", \"CON VIOLENCIA\", \"SIN VIOLENCIA\", \"ROBO DE GANADO (ABIGEATO)\", \"ROBO EN INSTITUCIONES BANCARIAS\", \"CON VIOLENCIA\", \"SIN VIOLENCIA\", \"ROBO EN CARRETERAS\", \"CON VIOLENCIA\", \"SIN VIOLENCIA\", \"TOTAL DE LESIONES\", \"DOLOSAS\", \"CULPOSAS\", \"TOTAL DE HOMICIDIOS\", \"DOLOSOS\", \"CULPOSOS\", \"DELITOS PATRIMONIALES\", \"PRIV DE LA LIBERTAD (SECUESTRO)\", \"DELITOS SEXUALES (VIOLACION)\", \"OTROS DELITOS\", \"AMENAZAS\", \"ESTUPRO\", \"OTROS SEXUALES\", \"RESTO DE LOS DELITOS (OTROS)\",\"AMENAZAS\",\"ESTUPRO\",\"OTROS SEXUALES\",\"RESTO DE LOS DELITOS (OTROS)\"]\n",
        "    noInclude = [\"ABUSO DE CONFIANZA\",\"DAÑO EN PROPIEDAD AJENA\",\"EXTORSION\",\"FRAUDE\",\"DESPOJO\"]\n",
        "    #Se recorren las posiciones de los documetnos en el arreglo de entrada\n",
        "    for i in datos:\n",
        "        #Se procede a descargar el documento por su id y se almacena con el año de procedencia\n",
        "        gd.download_file_from_google_drive(file_id=i['id'],\n",
        "        dest_path='./'+i[\"name\"]+'.pdf')\n",
        "        if int(i[\"name\"]) >2009:\n",
        "            page = 12\n",
        "        else:\n",
        "            page = 11\n",
        "        first = read_pdf('./'+i[\"name\"]+'.pdf',pages=int(page), output_format=\"dataframe\")\n",
        "        df = first[0]\n",
        "        print(df)\n",
        "        filtrados = pd.DataFrame(columns=df.columns.copy())\n",
        "\n",
        "        for j in df[\"CONCEPTO\"]:\n",
        "          try:\n",
        "            temp = j.replace(\".\",\"\")\n",
        "            temp = re.sub(\"\\d\", '', temp)\n",
        "            if(temp in diccionario or int(i[\"name\"])<2001):\n",
        "              filtrados.loc[len(filtrados)] = df.loc[df[df[\"CONCEPTO\"]==j].index.item(),:]\n",
        "          except:\n",
        "            pass\n",
        "        delitos.append({i[\"name\"] : filtrados.to_json(orient='records')})\n",
        "        os.remove(\"./\"+i[\"name\"]+\".pdf\")\n",
        "\n",
        "noPdf()\n",
        "getDocumentsCrimen(datos())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhmuLfbmyav9",
        "colab_type": "text"
      },
      "source": [
        "Se obtienen los datos del producto interno bruto de un intermediario con fuente original en el INEGI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGIDIboPyCsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def datosPIB(): \n",
        "    #Declaramos la URL de donde se van a obtener los link de los documentos\n",
        "    url='http://www.mexicomaxico.org/Voto/PIBMex.htm'\n",
        "    todos = pd.DataFrame(columns=[\"año\",\"PIB base\",\"%\"])    \n",
        "    crecimiento = []\n",
        "    filtro1 = []\n",
        "    \n",
        "    #Abrimos la url con el metodo GET\n",
        "    resp=requests.get(url) \n",
        "\n",
        "    #Validamos el status de la conexion, si es un status 200 entonces proseguimos\n",
        "    if resp.status_code==200: \n",
        "        print(\"Se conecto Correctamente a la fuente\\n\") \n",
        "        #Convertimos la pagina a texto con todas sus etiquetas\n",
        "        soup=BeautifulSoup(resp.text,'html.parser')     \n",
        "        #Buscamos los segmentos de tablas que vamos a utilizar\n",
        "        l=soup.find(\"table\",{\"id\":\"table167\"}) \n",
        "        #Se recorren los elementos. primero las filas y luego las columnas\n",
        "        for j in l.findAll(\"tr\"):\n",
        "          for i in j.findAll(\"td\"):\n",
        "            #Se valida que la columna actual tenga un valor\n",
        "\n",
        "            if(len(i.text)>1 and i.text != \" \"):            \n",
        "              try:\n",
        "                #Se remplazan espacios en blanco, saltos de linea, comas y asteriscos\n",
        "                valor = i.text.replace(\"\\t\",\"\").replace(\" \",\"\").replace(\"\\s\",\"\").replace(\"\\r\",\"\").replace(\"\\n\",\"\").replace(\",\",\"\").replace(\"*\",\"\")\n",
        "                #Se busca por letras dentro dentro del valor de la casilla, si no tiene letras y son puros numero entonces se almacena en el arreglo de crecimiento\n",
        "                if(re.search('[a-zA-Z]', valor) is None):\n",
        "                  crecimiento.append(valor)\n",
        "              except:\n",
        "                pass \n",
        "        #Se recorre el arreglo de crecimiento       \n",
        "        for i in crecimiento:\n",
        "          try:\n",
        "            #Si el valor actual es mayor a 1996 y menor a 2018 entonces se guarda en un segundo filtro seguido de sus siguientes 2 filas\n",
        "            if(int(i)>1996 and int(i)<2018):\n",
        "              filtro1.append(crecimiento[crecimiento.index(i):crecimiento.index(i)+3])\n",
        "          except:\n",
        "            pass\n",
        "        #Se recorre el filtro y se almacenan los valores dentro de el dataframe\n",
        "        for row in filtro1:\n",
        "          todos.loc[len(todos)] = row        \n",
        "        #Se eliminan los valores duplicados y se reinicia el conteo de index\n",
        "        todos = todos.drop_duplicates().reset_index(drop=True)\n",
        "        print(todos)\n",
        "    else: \n",
        "        print(\"Error\")\n",
        "    \n",
        "    return todos\n",
        "\n",
        "datosPIB()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtvXNCr3yiLw",
        "colab_type": "text"
      },
      "source": [
        "Se obtienen los datos de variaciones de inflación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1WORTDjzEGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#INCP || Inflacion\n",
        "url='http://www.mexicomaxico.org/Voto/InflacionMexico.htm'\n",
        "resp=requests.get(url) \n",
        "#Creacion de arreglos para filtrado\n",
        "full = []\n",
        "filt = []\n",
        "valores = [[],[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
        "#Arreglos con columnas y filtros\n",
        "meses = [\"Enero\",\"Febrero\",\"Marzo\",\"Abril\",\"Mayo\",\"Junio\",\"Julio\",\"Agosto\",\"Septiembre\",\"Octubre\",\"Noviembre\",\"Diciembre\",\"Inflación/año\"]\n",
        "annos = [\"1997\",\"1998\",\"1999\",\"2000\",\"2001\",\"2002\",\"2003\",\"2004\",\"2005\",\"2006\",\"2007\",\"2008\",\"2009\",\"2010\",\"2011\",\"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\"]\n",
        "#Creacion de dataframe\n",
        "final = pd.DataFrame(columns=[\"Año\",\"Enero\",\"Febrero\",\"Marzo\",\"Abril\",\"Mayo\",\"Junio\",\"Julio\",\"Agosto\",\"Septiembre\",\"Octubre\",\"Noviembre\",\"Diciembre\",\"Inflación/año\"])\n",
        "if resp.status_code==200: \n",
        "  print(\"Se conecto Correctamente a la fuente\\n\") \n",
        "  #Convertimos la pagina a texto con todas sus etiquetas\n",
        "  soup=BeautifulSoup(resp.text,'html.parser')     \n",
        "  #Buscamos los segmentos de tablas que vamos a utilizar\n",
        "  l=soup.find(\"table\",{\"id\":\"table206\"}) \n",
        "  #Se recorren todas las filas del sitio\n",
        "  for i in l.findAll(\"tr\"):\n",
        "    #Se filtran los espacios, saltos de linea y metadatas, de igual manera se separa por tabuladores\n",
        "    valor = i.text.replace(\"\\r\",\"\").replace(\"\\n\",\"\").replace(\" \",\"\").replace(\"\\xa0\",\"\").split(\"\\t\")\n",
        "    #Se valida que el valor de la casilla no sea nula o solo un espacio\n",
        "    if(valor is not None and len(valor)>1 and valor is not \"\"):\n",
        "      filtro = []\n",
        "      #Se recorren los valores de la pagina\n",
        "      for j in valor:\n",
        "       #Se deprecia el valor si este es nulo \n",
        "        if(j is not \"\" and j is not \" \" and j is not None):\n",
        "          filtro.append(j)\n",
        "      #Se añade a full el valor del arreglo generado\n",
        "      full.append(filtro)\n",
        "  #Se recorren los valores del arreglo completo\n",
        "  for j in full:\n",
        "    #Si el valor del arreglo tiene una longitud menor a 7 se deprecia\n",
        "    if(len(j)<7):\n",
        "      pass\n",
        "    #Si la longitud es de 7 se le añade al primer valor \"Año/mes\"\n",
        "    if(len(j) is 7):\n",
        "      j.insert(0,\"año/mes\")\n",
        "    #si la longitud es mayor a 6 entnces se añade al filtro\n",
        "    if(len(j)>6):\n",
        "      if(j[0] in meses):\n",
        "        filt.append(j)\n",
        "      if(j[1] in annos):\n",
        "        filt.append(j)\n",
        "  #Se recorre una copia del arreglo filt\n",
        "  for j in filt[:]:\n",
        "    #Cuando el primer valor sea año/mes se detiene el for, de lo contrario se eliminan los valores\n",
        "    if(j[0] == \"año/mes\"):\n",
        "      break\n",
        "    else:\n",
        "      filt.remove(j)\n",
        "  \n",
        "  #Se recorre el filtro y se empiezan a separar en subarreglos\n",
        "  for j in filt:\n",
        "    if(j[0] == \"año/mes\"):\n",
        "      for i in j:\n",
        "        if(re.match(\"[a-zA-Z]\",i)):\n",
        "          pass\n",
        "        else:\n",
        "          valores[0].append(i)\n",
        "    elif(j[0] == \"Enero\"):\n",
        "      for i in j:\n",
        "        if(re.match(\"[a-zA-Z]\",i)):\n",
        "          pass\n",
        "        else:\n",
        "          valores[1].append(i) \n",
        "    elif(j[0] == \"Febrero\"):\n",
        "      for i in j:\n",
        "        if(re.match(\"[a-zA-Z]\",i)):\n",
        "          pass\n",
        "        else:\n",
        "          valores[2].append(i) \n",
        "    elif(j[0] == \"Marzo\"):\n",
        "      for i in j:\n",
        "        if(re.match(\"[a-zA-Z]\",i)):\n",
        "          pass\n",
        "        else:\n",
        "          valores[3].append(i) \n",
        "    elif(j[0] == \"Abril\"):\n",
        "      for i in j:\n",
        "        if(re.match(\"[a-zA-Z]\",i)):\n",
        "          pass\n",
        "        else:\n",
        "          valores[4].append(i) \n",
        "    elif(j[0] == \"Mayo\"):\n",
        "      for i in j:\n",
        "        if(re.match(\"[a-zA-Z]\",i)):\n",
        "          pass\n",
        "        else:\n",
        "          valores[5].append(i) \n",
        "    elif(j[0] == \"Junio\"):\n",
        "      for i in j:\n",
        "        if(re.match(\"[a-zA-Z]\",i)):\n",
        "          pass\n",
        "        else:\n",
        "          valores[6].append(i) \n",
        "    elif(j[0] == \"Julio\"):\n",
        "      for i in j:\n",
        "        if(re.match(\"[a-zA-Z]\",i)):\n",
        "          pass\n",
        "        else:\n",
        "          valores[7].append(i) \n",
        "    elif(j[0] == \"Agosto\"):\n",
        "      for i in j:\n",
        "        if(re.match(\"[a-zA-Z]\",i)):\n",
        "          pass\n",
        "        else:\n",
        "          valores[8].append(i) \n",
        "    elif(j[0] == \"Septiembre\"):\n",
        "      for i in j:\n",
        "        if(re.match(\"[a-zA-Z]\",i)):\n",
        "          pass\n",
        "        else:\n",
        "          valores[9].append(i) \n",
        "    elif(j[0] == \"Octubre\"):\n",
        "      for i in j:\n",
        "        if(re.match(\"[a-zA-Z]\",i)):\n",
        "          pass\n",
        "        else:\n",
        "          valores[10].append(i) \n",
        "    elif(j[0] == \"Noviembre\"):\n",
        "      for i in j:\n",
        "        if(re.match(\"[a-zA-Z]\",i)):\n",
        "          pass\n",
        "        else:\n",
        "          valores[11].append(i) \n",
        "    elif(j[0] == \"Diciembre\"):\n",
        "      for i in j:\n",
        "        if(re.match(\"[a-zA-Z]\",i)):\n",
        "          pass\n",
        "        else:\n",
        "          valores[12].append(i) \n",
        "    elif(j[0] == \"Inflación/año\"):\n",
        "      for i in j:\n",
        "        if(re.match(\"[a-zA-Z]\",i)):\n",
        "          pass\n",
        "        else:\n",
        "          valores[13].append(i) \n",
        "  #Se convierte en un arreglo del tipo numpy\n",
        "  valores = np.array(valores)\n",
        "  print(valores)\n",
        "  #Se hace un transpose y se añaden al valor final de salida\n",
        "  for i in valores.transpose():\n",
        "    final.loc[len(final)] = i\n",
        "  insertable = json.loads(final.to_json(orient='records'))\n",
        "  print(insertable)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlccS3550zZm",
        "colab_type": "text"
      },
      "source": [
        "Se obtienen los datos de seguridad en el lapso correspondiente, como podemos observar en este caso la fuente es el diario economico \"*Expansion*\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWSrJl3l0yXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seguridad(): \n",
        "    #Declaramos la URL de donde se van a obtener los link de los documentos\n",
        "    url='https://datosmacro.expansion.com/estado/gasto/defensa/mexico'\n",
        "    todos = pd.DataFrame(columns=[\"Fecha\",\"Gasto Defenza\",\"Defenza Publica\",\"Defenza PIB\",\"Defenza\",\"Gasto Per Capita\"])    \n",
        "    crecimiento = []\n",
        "    filtro1 = []\n",
        "\n",
        "    #Abrimos la url con el metodo GET\n",
        "    resp=requests.get(url) \n",
        "\n",
        "    #Validamos el status de la conexion, si es un status 200 entonces proseguimos\n",
        "    if resp.status_code==200: \n",
        "        print(\"Se conecto Correctamente a la fuente\\n\") \n",
        "        #Convertimos la pagina a texto con todas sus etiquetas\n",
        "        soup=BeautifulSoup(resp.text,'html.parser')     \n",
        "        #Buscamos los segmentos de tablas que vamos a utilizar\n",
        "        l=soup.find(\"table\",{\"id\":\"tb0\"}) \n",
        "        #return print(l.text)\n",
        "        #Se recorren los elementos. primero las filas y luego las columnas\n",
        "        for j in l.findAll(\"tr\"): # Recorremos las filas\n",
        "          for i in j.findAll(\"td\"): # Recorrecmos las columnas\n",
        "            #Se valida que la columna actual tenga un valor\n",
        "            if(len(i.text)>1 and i.text != \" \"):            \n",
        "              try:\n",
        "                #Se remplazan espacios en blanco, saltos de linea, comas y asteriscos\n",
        "                valor = i.text.replace(\"\\t\",\"\").replace(\" \",\"\").replace(\"\\s\",\"\").replace(\"\\r\",\"\").replace(\"\\n\",\"\").replace(\",\",\",\").replace(\"*\",\"\").replace(\"€\",\"\")\n",
        "                crecimiento.append(valor)\n",
        "              except:\n",
        "                pass \n",
        "\n",
        "        #return print(crecimiento)\n",
        "\n",
        "        #Se recorre el arreglo de crecimiento       \n",
        "        for i in crecimiento:\n",
        "          try:\n",
        "            #Si el valor actual es mayor a 1996 y menor a 2018 entonces se guarda en un segundo filtro seguido de sus siguientes 2 filas\n",
        "            if(int(i)>1996 and int(i)<2018):\n",
        "              filtro1.append(crecimiento[crecimiento.index(i):crecimiento.index(i)+6])\n",
        "          except:\n",
        "            pass\n",
        "\n",
        "        #return print(filtro1)      \n",
        "\n",
        "        #Se recorre el filtro y se almacenan los valores dentro de el dataframe\n",
        "        for row in filtro1:\n",
        "          todos.loc[len(todos)] = row      \n",
        "            \n",
        "        #Se eliminan los valores duplicados y se reinicia el conteo de index\n",
        "        todos = todos.drop_duplicates().reset_index(drop=True)\n",
        "        \n",
        "        print(todos)\n",
        "\n",
        "\n",
        "    else: \n",
        "        print(\"Error\")\n",
        "\n",
        "seguridad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymKHDYI91a98",
        "colab_type": "text"
      },
      "source": [
        "Ciertos datos de economia han sido proporcionado por los sitios oficiales en formatos CSV, es por ello que para hacer el acceso a estos mas sencillo se han subido a una carpeta en google drive y son consumidos automaticamente por los siguientes segmentos de codigo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tShuBuOwPfq2",
        "colab_type": "text"
      },
      "source": [
        "El primer caso en el que podemos ver que hay un documento externo es el caso del ingreso Per Capita, el cual se consulta directamente por su id en google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDUwaO1c1G0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Archivo CSV Per Capita\n",
        "gd.download_file_from_google_drive(file_id=\"1UOO1zZAb3uCgRvlC8f3UzbnOmkcjheQn\",\n",
        "        dest_path='./Per_Carpita.csv')\n",
        "df=pd.read_csv('Per_Carpita.csv')\n",
        "\n",
        "print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAyXyMJEPs0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Archivo CSV Inversion\n",
        "gd.download_file_from_google_drive(file_id=\"1BDlR_s1XQWJsGyctxHEtWZWrf33PAQxF\",\n",
        "        dest_path='./inversion.csv')\n",
        "noIterable = [\"1980\",\"1981\",\"1982\",\"1983\",\"1984\",\"1985\",\"1986\",\"1987\",\"1988\",\"1989\",\"1990\",\"1991\",\"1992\",\"1993\",\"1994\",\"1995\",\"1996\",\"2018\",\"2019\"]\n",
        "df=pd.read_csv('inversion.csv')\n",
        "\n",
        "df = df.fillna(value=0)\n",
        "\n",
        "toDelete = []\n",
        "\n",
        "for i in df[\"Periodo\"]:\n",
        "  if(i in noIterable):\n",
        "    toDelete.append(df.loc[df[\"Periodo\"] == i].index.tolist()[0])\n",
        "\n",
        "df = df.drop(df.index[toDelete])\n",
        "\n",
        "print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpgZUfzmQLT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Salario Minimo \n",
        "gd.download_file_from_google_drive(file_id=\"1SktOPiYnJraStqLo-7BpiBpEL7yrMxWl\",\n",
        "        dest_path='./Minimo.csv')\n",
        "\n",
        "df = pd.read_csv('Minimo.csv')\n",
        "\n",
        "noIterable = [1989,1990,1991,1992,1993,1994,1995,1996,2018,2019]\n",
        "\n",
        "df = df.fillna(value=0)\n",
        "\n",
        "toDelete = []\n",
        "\n",
        "for i in df[\"Año\"]:\n",
        "  if i in noIterable:\n",
        "    toDelete.append(df.loc[df[\"Año\"] == i].index.tolist()[0])\n",
        "\n",
        "df = df.drop(df.index[toDelete])\n",
        "\n",
        "print(df.reset_index(drop=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L0XYE1UQjIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Empleos Formales\n",
        "gd.download_file_from_google_drive(file_id=\"1b6jPo-s3q6hanqb67JbkhpTxzcxAdFCe\",\n",
        "        dest_path='./EmpleoFormal.csv')\n",
        "#Creamos un arreglo con las fechas que no queremos mostrar\n",
        "noIterable = [\"2018\",\"2019\"]\n",
        "#Llamamos a el documento CSV y lo convertimos en un dataframe\n",
        "df=pd.read_csv('EmpleoFormal.csv')\n",
        "#Creamo un arreglo de para almacenar los elementos que  queremos eliminar\n",
        "toDelete = []\n",
        "#Si el documento tiene alguna celda vacia la rellenamos con el valor de 0\n",
        "df = df.fillna(value=0)\n",
        "#Recorremos el DataFrame el la columna del Año/Mes\n",
        "for i in df[\"Año/Mes\"]:\n",
        "  for n in noIterable: #Recorremos el arreglo de los elementos que queremos eliminar\n",
        "    if(n in i): #Comprobamos que  los elementos coicidadn para almacenarlos en el arreglo \n",
        "      toDelete.append(df.loc[df[\"Año/Mes\"] == i].index.tolist()[0]) #Almacenamos en el arreglo toDelete\n",
        "      break\n",
        "      \n",
        "df = df.drop(df.index[toDelete]) #Eliminamos todos los elementos que no queremos en el DataFrame \n",
        "\n",
        "print(df) #Imprimimos el dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VXRXZNCR0AJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Informales\n",
        "gd.download_file_from_google_drive(file_id=\"19w2BUrfSotXn4pGFLPC-HaDFF5lSnxqs\",\n",
        "        dest_path='./EmpleoInfomales.csv')\n",
        "\n",
        "df=pd.read_csv('EmpleoInfomales.csv')\n",
        "#Faltan los datos del 2010 a 2017\n",
        "print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFeP8BsNSLtX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#IVA\n",
        "gd.download_file_from_google_drive(file_id=\"1dA3aL9jHBisH_9iRGEbX_WSvInAIsMtD\",\n",
        "        dest_path='./IVA.csv')\n",
        "df=pd.read_csv('IVA.csv')\n",
        "print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvj19VHZSad1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gd.download_file_from_google_drive(file_id=\"1oDurEnLB0_66g3ifH_rjOdHKLG36tdDw\",\n",
        "        dest_path='./inversionHistorica.csv')\n",
        "df=pd.read_csv('inversionHistorica.csv')\n",
        "noIterable = [1996,2018]\n",
        "\n",
        "df = df.fillna(value=0)\n",
        "\n",
        "toDelete = []\n",
        "\n",
        "for i in df[\"Año\"]:\n",
        "  if i in noIterable:\n",
        "    toDelete.append(df.loc[df[\"Año\"] == i].index.tolist()[0])\n",
        "df = df.drop(df.index[toDelete])\n",
        "\n",
        "print(df.reset_index(drop=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoOhkiU1V2x6",
        "colab_type": "text"
      },
      "source": [
        "Para la generación del modelo matematico es importante hacer primero una interpretacion de los datos que se almacenaron previamente en la base de datos, la primera fase de la generación del modelo es crear graficas de cada uno de los dataset para poder observar su comportamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRPoZ3b-V1dy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collection = db[\"CRIMEN\"]\n",
        "cursor = collection.find({})\n",
        "year = 2017\n",
        "labels = [\"ENERO\",\"FEBRERO\",\"MARZO\",\"ABRIL\",\"MAYO\",\"JUNIO\",\"JULIO\",\"AGOSTO\",\"SEPTIEMBRE\",\"OCTUBRE\",\"NOVIEMBRE\",\"DICIEMBRE\"]\n",
        "for document in cursor:\n",
        "    datos = json.loads(document.get(str(year)))\n",
        "    conceptos = []\n",
        "    meses = {}\n",
        "    meses[\"ENERO\"] = []\n",
        "    meses[\"FEBRERO\"] = []\n",
        "    meses[\"MARZO\"] = []\n",
        "    meses[\"ABRIL\"] = []\n",
        "    meses[\"MAYO\"] = []\n",
        "    meses[\"JUNIO\"] = []\n",
        "    meses[\"JULIO\"] = []\n",
        "    meses[\"AGOSTO\"] = []\n",
        "    meses[\"SEPTIEMBRE\"] = []\n",
        "    meses[\"OCTUBRE\"] = []\n",
        "    meses[\"NOVIEMBRE\"] = []\n",
        "    meses[\"DICIEMBRE\"] = []\n",
        "    meses[\"TOTAL\"] = []\n",
        "    for concepto in datos:\n",
        "      for tipo in concepto:\n",
        "        if(tipo == \"CONCEPTO\"):\n",
        "          concep = concepto[tipo]\n",
        "          conceptos.append(concepto[tipo])\n",
        "        else:\n",
        "          meses[tipo].append(concepto[tipo])\n",
        "\n",
        "    df = pd.DataFrame(data=meses)\n",
        "\n",
        "    df.fillna(value=0, inplace=True)\n",
        "\n",
        "    for nombre in df.index:\n",
        "      df.rename(index={nombre:conceptos[nombre]},inplace=True)\n",
        "    \n",
        "    fig = plt.figure()\n",
        "    ax1 = fig.add_subplot(111)\n",
        "    for i,a in zip(range(1,len(df.index)),df.index):\n",
        "      ax1.plot(df.columns, df.loc[a,:],c=np.random.rand(3,),label = a)\n",
        "      ax1.legend(loc='upper left')\n",
        "    fig.set_size_inches(20.0, 30)\n",
        "    \n",
        "    year -= 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lVuB_1JwdoY",
        "colab_type": "text"
      },
      "source": [
        "La graficacion de los empleos formales en la ciudad de mexico se muestra en una grafica de puntos, para tener una mejor nocion de las variaciones entre los valores y sus tendencias, podemos observar que aun cuando la cantidad de empleos generados es baja, la cantidad de empleos formales es bastante grande."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaTEuPN1wfKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collection = db[\"FORMALES\"]\n",
        "for anno in range(1997,2018):\n",
        "  meses = []\n",
        "  cantAcum = []\n",
        "  geneAcum = []\n",
        "  acumAcum = []\n",
        "  \n",
        "  rgx = re.compile(str(anno)+\"\\/\\d{2}\")\n",
        "  cursor = collection.find({'Año/Mes':rgx})\n",
        "\n",
        "  for document in cursor:\n",
        "    meses.append(document[\"Año/Mes\"].split(\"/\")[1]) \n",
        "    cantAcum.append(float(str(document[\"Empleos formales totales\"]).replace(\",\",\"\")))\n",
        "    geneAcum.append(float(str(document[\"Generación de empleo formal mensual\"]).replace(\",\",\"\")))\n",
        "    acumAcum.append(float(str(document[\"Empleos generados acumulados en el año\"]).replace(\",\",\"\")))\n",
        "\n",
        "  plt.scatter(meses,cantAcum, label=\"Empleos formales totales\")\n",
        "  plt.scatter(meses,geneAcum, label=\"Generación de empleo formal mensual\")\n",
        "  plt.scatter(meses,acumAcum, label=\"Empleos generados acumulados en el año\")\n",
        "\n",
        "  plt.legend(loc='best')\n",
        "  plt.title(\"Empleos formales en el año \"+str(anno), fontsize=16, fontweight='bold')\n",
        "  plt.xlabel(\"Mes\")\n",
        "  plt.ylabel(\"Cantidad\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT7iQHPzwksP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collection = db[\"INFORMALES\"]\n",
        "for anno in range(1997,2018):\n",
        "  trimestresH = []\n",
        "  trimestresM = []\n",
        "\n",
        "  pOcupadaH = []\n",
        "  pOcupadaIH = []\n",
        "  tInforH = []\n",
        "  eTotalesH = []\n",
        "  pOcupadaM = []\n",
        "  pOcupadaIM = []\n",
        "  tInforM = []\n",
        "  eTotalesM = []\n",
        "\n",
        "  rgx = re.compile(str(anno)+\"\\/\\d{2}\")\n",
        "  cursor = collection.find({'Año/Trimestre':rgx})\n",
        "\n",
        "  for document in cursor:  \n",
        "\n",
        "    if(document[\"Sexo\"] == \"Hombre\"):\n",
        "      trimestresH.append(document[\"Año/Trimestre\"].split(\"/\")[1])\n",
        "      pOcupadaH.append(document[\"Poblacion_Ocupada\"])\n",
        "      pOcupadaIH.append(document[\"Poblacion_Ocupada_empleo_informal\"])\n",
        "      tInforH.append(document[\"Tasa de Informailidad_Laboral_1\"])\n",
        "      eTotalesH.append(document[\"Empleos_Totales\"])\n",
        "    else:\n",
        "      trimestresM.append(document[\"Año/Trimestre\"].split(\"/\")[1])\n",
        "      pOcupadaM.append(document[\"Poblacion_Ocupada\"])\n",
        "      pOcupadaIM.append(document[\"Poblacion_Ocupada_empleo_informal\"])\n",
        "      tInforM.append(document[\"Tasa de Informailidad_Laboral_1\"])\n",
        "      eTotalesM.append(document[\"Empleos_Totales\"])\n",
        "\n",
        "  plt.scatter(trimestresH,pOcupadaH, label=\"Poblacion ocupada\")\n",
        "  plt.scatter(trimestresH,pOcupadaIH, label=\"Poblacion ocupada empleo informal\")\n",
        "  plt.scatter(trimestresH,tInforH, label=\"Tasa de informalidad \")\n",
        "  plt.scatter(trimestresH,eTotalesH, label=\"Empleos totales \")\n",
        "\n",
        "  plt.legend(loc='best')\n",
        "  plt.title(\"Empleos informales en el año \"+str(anno)+\" en Hombres\", fontsize=16, fontweight='bold')\n",
        "  plt.xlabel(\"Trimestre\")\n",
        "  plt.ylabel(\"Cantidad\")\n",
        "  plt.show()\n",
        "  \n",
        "  plt.scatter(trimestresM,pOcupadaM, label=\"Poblacion ocupada\")\n",
        "  plt.scatter(trimestresM,pOcupadaIM, label=\"Poblacion ocupada empleo informal\")\n",
        "  plt.scatter(trimestresM,tInforM, label=\"Tasa de informalidad\")\n",
        "  plt.scatter(trimestresM,eTotalesM, label=\"Empleos totales\")\n",
        "\n",
        "  plt.legend(loc='best')\n",
        "  plt.title(\"Empleos informales en el año \"+str(anno)+\" en Mujeres\", fontsize=16, fontweight='bold')\n",
        "  plt.xlabel(\"Trimestre\")\n",
        "  plt.ylabel(\"Cantidad\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeNUBEscwyzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collection = db[\"INFRAESTRUCTURA\"]\n",
        "cursor = collection.find({})\n",
        "\n",
        "years = []\n",
        "energy = []\n",
        "comunications = []\n",
        "education = []\n",
        "health = []\n",
        "wather = []\n",
        "others = []\n",
        "total = []\n",
        "\n",
        "for document in cursor:\n",
        "  years.append(document[\"Año\"])\n",
        "  energy.append(document[\"Energético\"])\n",
        "  comunications.append(document[\"Comunicaciones y Transportes\"])\n",
        "  education.append(document[\"Educación\"])\n",
        "  health.append(document[\"Salud\"])\n",
        "  wather.append(document[\"Abastecimiento, Agua Potable y Alcantarillado\"])\n",
        "  others.append(document[\"Otros\"])\n",
        "  total.append(document[\"TOTAL\"])\n",
        "\n",
        "plt.plot(years,energy,label=\"Energético\", color= \"b\")\n",
        "plt.plot(years,comunications,label=\"Comunicaciones y Transportes\", color= \"g\")\n",
        "plt.plot(years,education,label=\"Educación\", color= \"r\")\n",
        "plt.plot(years,health,label=\"Salud\", color= \"c\")\n",
        "plt.plot(years,wather,label=\"Abastecimiento, Agua Potable y Alcantarillado\", color= \"m\")\n",
        "plt.plot(years,others,label=\"Otros\", color= \"y\")\n",
        "plt.plot(years,total,label=\"Total\", color= \"k\", linestyle= \":\")\n",
        "plt.legend(loc='best')\n",
        "plt.title(\"Inversion en materia de infraestructura 1997-2017\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"Año\")\n",
        "plt.ylabel(\"%\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJU3kIU1w2Jw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collection = db[\"INVERSION\"]\n",
        "rgx = re.compile(\"^\\d{4}$\")\n",
        "rgx2 = re.compile(\"^\\d{4}\\s-\\sI{1,3}$\")\n",
        "anual = collection.find({\"Periodo\":rgx})\n",
        "trimestral = collection.find({\"Periodo\":rgx2})\n",
        "\n",
        "anno = []\n",
        "periodo = []\n",
        "total = []\n",
        "directa = []\n",
        "cartera = []\n",
        "\n",
        "for document in anual:\n",
        "  tmp = document[\"Total\"].replace(\",\",\"\")\n",
        "  tmp = tmp.split(\".\")\n",
        "  final = \"\"\n",
        "  for index, item in enumerate(tmp):\n",
        "    if(index == len(tmp)-1):\n",
        "      final += \".\" + tmp[index]\n",
        "      break\n",
        "    final += tmp[index]\n",
        "    \n",
        "  anno.append(document[\"Periodo\"])\n",
        "  total.append(float(final))\n",
        "  directa.append(float(str(document[\"Directa\"]).replace(\",\",\"\")))\n",
        "  cartera.append(float(str(document[\"Cartera\"]).replace(\",\",\"\")))\n",
        "\n",
        "plt.plot(anno,total,label=\"Inversion total\", color= \"r\")\n",
        "plt.plot(anno,directa,label=\"Inversion directa\", color= \"g\")\n",
        "plt.plot(anno,cartera,label=\"Inversion Cartera\", color= \"b\")\n",
        "plt.legend(loc='best')\n",
        "plt.title(\"Inversion 1997-2017\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"Año\")\n",
        "plt.ylabel(\"Inversion\")\n",
        "plt.show()\n",
        "\n",
        "total.clear()\n",
        "directa.clear()\n",
        "cartera.clear()\n",
        "\n",
        "for document in trimestral:\n",
        "  tmp = document[\"Total\"].replace(\",\",\"\")\n",
        "  tmp = tmp.split(\".\")\n",
        "  final = \"\"\n",
        "  for index, item in enumerate(tmp):\n",
        "    if(index == len(tmp)-1):\n",
        "      final += \".\" + tmp[index]\n",
        "      break\n",
        "    final += tmp[index]\n",
        "  periodo.append(document[\"Periodo\"])\n",
        "  total.append(float(final))\n",
        "  directa.append(float(str(document[\"Directa\"]).replace(\",\",\"\")))\n",
        "  cartera.append(float(str(document[\"Cartera\"]).replace(\",\",\"\")))\n",
        "\n",
        "plt.plot(periodo,total,label=\"Inversion total\", color= \"r\")\n",
        "plt.plot(periodo,directa,label=\"Inversion directa\", color= \"g\")\n",
        "plt.plot(periodo,cartera,label=\"Inversion Cartera\", color= \"b\")\n",
        "plt.legend(loc='best')\n",
        "plt.title(\"Inversion 1997-2017\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"Periodo\")\n",
        "plt.ylabel(\"Inversion\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgi0ATP23_eq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collection = db[\"IVA\"]\n",
        "\n",
        "rgx = re.compile(\"^\\d{4}$\")\n",
        "anual = collection.find({\"Año   \":rgx})\n",
        "\n",
        "anno = []\n",
        "tasas = []\n",
        "guion = []\n",
        "pib = []\n",
        "porcentaje = []\n",
        "\n",
        "for document in anual:\n",
        "  anno.append(document[\"Año   \"])\n",
        "  tasas.append(document[\"      Tasas\"])\n",
        "  guion.append(document[\"-\"])\n",
        "  pib.append(float(document[\" % PIB\"]))\n",
        "  porcentaje.append(float(document[\"%\"]))\n",
        "\n",
        "plt.plot(anno,tasas,label=\"Tasas de Iva\", color= \"r\")\n",
        "plt.plot(anno,guion,label=\"IVA\", color= \"g\")\n",
        "plt.plot(anno,pib,label=\"Pib de Iva\", color= \"b\")\n",
        "plt.plot(anno,porcentaje,label=\"Porcentaje de Iva\", color= \"gray\")\n",
        "plt.legend(loc='best')\n",
        "plt.title(\"Iva 1997-2017\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"AÑO\")\n",
        "plt.ylabel(\"IVA\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcQPOTWn4E9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collection = db[\"SEGURIDAD\"]\n",
        "\n",
        "rgx = re.compile(\"^\\d{4}$\")\n",
        "anual = collection.find({\"Fecha\":rgx})\n",
        "\n",
        "anno = []\n",
        "gastoDefenza = []\n",
        "defenzaPublica = []\n",
        "defenzaPib = []\n",
        "defenza = []\n",
        "gastoPerCapita = []\n",
        "\n",
        "for document in anual:\n",
        "  anno.append(document[\"Fecha\"])\n",
        "  gastoDefenza.append(document[\"Gasto Defenza\"])\n",
        "  defenzaPublica.append(document[\"Defenza Publica\"])\n",
        "  defenzaPib.append(document[\"Defenza PIB\"])\n",
        "  defenza.append(document[\"Defenza\"])\n",
        "  gastoPerCapita.append(document[\"Gasto Per Capita\"])\n",
        "\n",
        "plt.plot(anno,gastoDefenza,label=\"Gasto de Defenza\", color= \"r\")\n",
        "plt.plot(anno,defenzaPublica,label=\"Defenza Publica\", color= \"g\")\n",
        "plt.plot(anno,defenzaPib,label=\"Defenza PIB\", color= \"b\")\n",
        "plt.plot(anno,defenza,label=\"Defenza\", color= \"gray\")\n",
        "plt.plot(anno,gastoPerCapita,label=\"Gasti Per Capita\", color= \"orange\")\n",
        "plt.legend(loc='best')\n",
        "plt.title(\"SEGURIDAD 1997-2017\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"AÑO\")\n",
        "plt.ylabel(\"SEGURIDAD\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
